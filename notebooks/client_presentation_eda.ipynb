{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üó∫Ô∏è Personalized Travel Itinerary System\n",
    "## Data Analysis & City Expansion Framework\n",
    "\n",
    "---\n",
    "\n",
    "### Executive Summary\n",
    "\n",
    "This analysis demonstrates our **RAG-based persona-driven itinerary system** using Rome as our pilot city. We analyze:\n",
    "\n",
    "1. **Data Coverage** - POI distribution across categories and neighborhoods\n",
    "2. **Persona Fit Analysis** - How well our data supports different traveler types\n",
    "3. **Geographic Clustering** - Optimal groupings for day-by-day itineraries\n",
    "4. **Restaurant Accessibility** - Dining options near attractions\n",
    "5. **Expansion Framework** - Scalable approach for adding new cities\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup - Run this first\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Clustering\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Set plotly template for consistent styling\n",
    "import plotly.io as pio\n",
    "pio.templates.default = \"plotly_white\"\n",
    "\n",
    "# Color palette\n",
    "COLORS = {\n",
    "    'primary': '#2E86AB',\n",
    "    'secondary': '#A23B72',\n",
    "    'accent': '#F18F01',\n",
    "    'success': '#C73E1D',\n",
    "    'neutral': '#3B1F2B'\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Rome POI Data\n",
    "def load_rome_data():\n",
    "    \"\"\"Load curated Rome POI data.\"\"\"\n",
    "    seed_path = Path(\"../data/seed/rome_pois.json\")\n",
    "    \n",
    "    if seed_path.exists():\n",
    "        with open(seed_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Flatten nested data\n",
    "        pois = []\n",
    "        for poi in data['pois']:\n",
    "            flat_poi = {k: v for k, v in poi.items() if k not in ['persona_scores', 'attributes']}\n",
    "            if 'persona_scores' in poi:\n",
    "                flat_poi.update(poi['persona_scores'])\n",
    "            if 'attributes' in poi:\n",
    "                flat_poi.update(poi['attributes'])\n",
    "            pois.append(flat_poi)\n",
    "        \n",
    "        return pd.DataFrame(pois), data.get('persona_templates', [])\n",
    "    return None, None\n",
    "\n",
    "df, persona_templates = load_rome_data()\n",
    "\n",
    "if df is not None:\n",
    "    print(f\"üìç Loaded {len(df)} POIs for Rome\")\n",
    "    print(f\"üë• Loaded {len(persona_templates)} persona templates\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Data not found. Please run seed script first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Data Coverage Analysis\n",
    "\n",
    "### Key Question: Do we have enough POIs across all categories to build quality itineraries?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category Distribution\n",
    "category_counts = df['category'].value_counts()\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=category_counts.index,\n",
    "    y=category_counts.values,\n",
    "    marker_color=[COLORS['primary'], COLORS['secondary'], COLORS['accent'], \n",
    "                  COLORS['success'], COLORS['neutral']][:len(category_counts)],\n",
    "    text=category_counts.values,\n",
    "    textposition='outside'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': '<b>POI Distribution by Category</b><br><sup>Rome Pilot Data</sup>',\n",
    "        'x': 0.5,\n",
    "        'xanchor': 'center'\n",
    "    },\n",
    "    xaxis_title='Category',\n",
    "    yaxis_title='Number of POIs',\n",
    "    height=400,\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Analysis\n",
    "print(\"\\nüìä CATEGORY COVERAGE ANALYSIS\")\n",
    "print(\"=\" * 40)\n",
    "total = len(df)\n",
    "for cat, count in category_counts.items():\n",
    "    pct = count/total*100\n",
    "    status = \"‚úÖ\" if count >= 5 else \"‚ö†Ô∏è\"\n",
    "    print(f\"{status} {cat.title()}: {count} POIs ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neighborhood Coverage\n",
    "neighborhood_counts = df['neighborhood'].value_counts()\n",
    "\n",
    "fig = px.treemap(\n",
    "    names=neighborhood_counts.index,\n",
    "    parents=['Rome'] * len(neighborhood_counts),\n",
    "    values=neighborhood_counts.values,\n",
    "    title='<b>POI Distribution by Neighborhood</b>',\n",
    "    color=neighborhood_counts.values,\n",
    "    color_continuous_scale='Blues'\n",
    ")\n",
    "\n",
    "fig.update_layout(height=500)\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nüìç NEIGHBORHOOD COVERAGE\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Total neighborhoods covered: {len(neighborhood_counts)}\")\n",
    "print(f\"\\nTop 5 neighborhoods by POI count:\")\n",
    "for i, (nb, count) in enumerate(neighborhood_counts.head().items(), 1):\n",
    "    print(f\"  {i}. {nb}: {count} POIs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category by Neighborhood Heatmap\n",
    "pivot = pd.crosstab(df['neighborhood'], df['category'])\n",
    "\n",
    "fig = px.imshow(\n",
    "    pivot,\n",
    "    title='<b>Category Coverage by Neighborhood</b><br><sup>Identifying gaps in data coverage</sup>',\n",
    "    labels=dict(x='Category', y='Neighborhood', color='POI Count'),\n",
    "    color_continuous_scale='YlOrRd',\n",
    "    aspect='auto'\n",
    ")\n",
    "\n",
    "fig.update_layout(height=500)\n",
    "fig.show()\n",
    "\n",
    "# Identify gaps\n",
    "print(\"\\nüîç DATA GAPS IDENTIFIED\")\n",
    "print(\"=\" * 40)\n",
    "gaps = []\n",
    "for nb in pivot.index:\n",
    "    for cat in pivot.columns:\n",
    "        if pivot.loc[nb, cat] == 0:\n",
    "            gaps.append(f\"  ‚Ä¢ No {cat}s in {nb}\")\n",
    "\n",
    "if gaps:\n",
    "    print(\"Missing combinations:\")\n",
    "    for gap in gaps[:10]:  # Show top 10\n",
    "        print(gap)\n",
    "else:\n",
    "    print(\"‚úÖ All neighborhood-category combinations covered!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Persona Fit Analysis\n",
    "\n",
    "### Key Question: How well does our POI data support different traveler personas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define persona score columns\n",
    "group_scores = ['score_family', 'score_couple', 'score_honeymoon', 'score_solo', \n",
    "                'score_friends', 'score_seniors', 'score_business']\n",
    "vibe_scores = ['score_adventure', 'score_relaxation', 'score_cultural', 'score_foodie',\n",
    "               'score_nightlife', 'score_nature', 'score_shopping', 'score_photography',\n",
    "               'score_wellness', 'score_romantic']\n",
    "\n",
    "# Filter available columns\n",
    "available_group = [c for c in group_scores if c in df.columns]\n",
    "available_vibe = [c for c in vibe_scores if c in df.columns]\n",
    "\n",
    "if available_group:\n",
    "    # Calculate average scores per persona\n",
    "    persona_avg = df[available_group].mean().sort_values(ascending=True)\n",
    "    \n",
    "    # Clean labels\n",
    "    labels = [s.replace('score_', '').title() for s in persona_avg.index]\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_trace(go.Bar(\n",
    "        y=labels,\n",
    "        x=persona_avg.values,\n",
    "        orientation='h',\n",
    "        marker_color=COLORS['primary'],\n",
    "        text=[f'{v:.2f}' for v in persona_avg.values],\n",
    "        textposition='outside'\n",
    "    ))\n",
    "    \n",
    "    # Add threshold line\n",
    "    fig.add_vline(x=0.7, line_dash=\"dash\", line_color=\"green\", \n",
    "                  annotation_text=\"Good Fit Threshold (0.7)\")\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='<b>Average POI Fit Score by Traveler Type</b><br><sup>Higher = Better suited for this persona</sup>',\n",
    "        xaxis_title='Average Score (0-1)',\n",
    "        yaxis_title='Traveler Type',\n",
    "        height=400,\n",
    "        xaxis_range=[0, 1]\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    print(\"\\nüë• PERSONA SUPPORT ANALYSIS\")\n",
    "    print(\"=\" * 40)\n",
    "    for persona, score in persona_avg.items():\n",
    "        name = persona.replace('score_', '').title()\n",
    "        if score >= 0.75:\n",
    "            print(f\"‚úÖ {name}: Excellent support ({score:.2f})\")\n",
    "        elif score >= 0.6:\n",
    "            print(f\"üü° {name}: Good support ({score:.2f})\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è {name}: Needs more POIs ({score:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vibe Coverage Radar Chart\n",
    "if available_vibe:\n",
    "    vibe_avg = df[available_vibe].mean()\n",
    "    labels = [s.replace('score_', '').title() for s in vibe_avg.index]\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_trace(go.Scatterpolar(\n",
    "        r=vibe_avg.values,\n",
    "        theta=labels,\n",
    "        fill='toself',\n",
    "        name='Rome',\n",
    "        line_color=COLORS['primary']\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        polar=dict(\n",
    "            radialaxis=dict(visible=True, range=[0, 1])\n",
    "        ),\n",
    "        title='<b>Vibe Coverage Analysis</b><br><sup>How well Rome supports different travel vibes</sup>',\n",
    "        height=500\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    # Top and bottom vibes\n",
    "    print(\"\\nüéØ VIBE STRENGTHS & GAPS\")\n",
    "    print(\"=\" * 40)\n",
    "    sorted_vibes = vibe_avg.sort_values(ascending=False)\n",
    "    print(\"\\nüí™ Strongest vibes:\")\n",
    "    for vibe, score in sorted_vibes.head(3).items():\n",
    "        print(f\"  ‚Ä¢ {vibe.replace('score_', '').title()}: {score:.2f}\")\n",
    "    print(\"\\nüìà Needs improvement:\")\n",
    "    for vibe, score in sorted_vibes.tail(3).items():\n",
    "        print(f\"  ‚Ä¢ {vibe.replace('score_', '').title()}: {score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Geographic Analysis & Clustering\n",
    "\n",
    "### Key Question: How should we group POIs for optimal day-by-day itineraries?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map all POIs\n",
    "fig = px.scatter_mapbox(\n",
    "    df,\n",
    "    lat='latitude',\n",
    "    lon='longitude',\n",
    "    color='category',\n",
    "    size_max=15,\n",
    "    hover_name='name',\n",
    "    hover_data=['neighborhood', 'cost_level'],\n",
    "    title='<b>Rome POI Distribution</b>',\n",
    "    zoom=12,\n",
    "    height=600,\n",
    "    color_discrete_sequence=px.colors.qualitative.Set2\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    mapbox_style='carto-positron',\n",
    "    margin={'r':0,'t':50,'l':0,'b':0}\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform clustering for itinerary optimization\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"Calculate distance in km.\"\"\"\n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    return 6371 * 2 * asin(sqrt(a))\n",
    "\n",
    "# DBSCAN clustering (walkable zones = 400m)\n",
    "coords = df[['latitude', 'longitude']].values\n",
    "coords_rad = np.radians(coords)\n",
    "\n",
    "eps_km = 0.4  # 400 meters - comfortable walking distance\n",
    "eps_rad = eps_km / 6371.0\n",
    "\n",
    "dbscan = DBSCAN(eps=eps_rad, min_samples=2, metric='haversine')\n",
    "df['walkable_zone'] = dbscan.fit_predict(coords_rad)\n",
    "\n",
    "n_zones = len(set(df['walkable_zone'])) - (1 if -1 in df['walkable_zone'].values else 0)\n",
    "n_isolated = (df['walkable_zone'] == -1).sum()\n",
    "\n",
    "print(f\"üìç WALKABLE ZONE ANALYSIS (400m radius)\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Walkable zones identified: {n_zones}\")\n",
    "print(f\"Isolated POIs: {n_isolated}\")\n",
    "print(f\"Clustered POIs: {len(df) - n_isolated}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize walkable zones\n",
    "df_clustered = df[df['walkable_zone'] >= 0].copy()\n",
    "\n",
    "fig = px.scatter_mapbox(\n",
    "    df_clustered,\n",
    "    lat='latitude',\n",
    "    lon='longitude',\n",
    "    color='walkable_zone',\n",
    "    hover_name='name',\n",
    "    hover_data=['category', 'neighborhood'],\n",
    "    title='<b>Walkable Zones for Itinerary Planning</b><br><sup>POIs within 400m grouped together</sup>',\n",
    "    zoom=12,\n",
    "    height=600,\n",
    "    color_continuous_scale='Viridis'\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    mapbox_style='carto-positron',\n",
    "    margin={'r':0,'t':50,'l':0,'b':0}\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Zone composition\n",
    "print(\"\\nüö∂ WALKABLE ZONE COMPOSITION\")\n",
    "print(\"=\" * 40)\n",
    "zone_analysis = df_clustered.groupby('walkable_zone').agg({\n",
    "    'name': 'count',\n",
    "    'category': lambda x: x.value_counts().to_dict(),\n",
    "    'neighborhood': 'first'\n",
    "}).rename(columns={'name': 'poi_count'})\n",
    "\n",
    "for zone_id, row in zone_analysis.iterrows():\n",
    "    cats = row['category']\n",
    "    has_attraction = cats.get('attraction', 0) > 0\n",
    "    has_restaurant = cats.get('restaurant', 0) > 0\n",
    "    \n",
    "    completeness = \"‚úÖ Self-contained\" if (has_attraction and has_restaurant) else \"‚ö†Ô∏è Needs pairing\"\n",
    "    \n",
    "    print(f\"\\nZone {zone_id} ({row['neighborhood']}):\")\n",
    "    print(f\"  POIs: {row['poi_count']} | {completeness}\")\n",
    "    print(f\"  Mix: {cats}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Restaurant Accessibility Analysis\n",
    "\n",
    "### Key Question: Do all major attractions have dining options nearby?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find restaurants near each attraction\n",
    "attractions = df[df['category'] == 'attraction'].copy()\n",
    "restaurants = df[df['category'] == 'restaurant'].copy()\n",
    "\n",
    "def count_nearby(poi, all_pois, max_km=0.5):\n",
    "    \"\"\"Count POIs within walking distance.\"\"\"\n",
    "    count = 0\n",
    "    for _, other in all_pois.iterrows():\n",
    "        if poi['name'] != other['name']:\n",
    "            dist = haversine(poi['longitude'], poi['latitude'], \n",
    "                           other['longitude'], other['latitude'])\n",
    "            if dist <= max_km:\n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "# Calculate for each attraction\n",
    "accessibility_data = []\n",
    "for _, attraction in attractions.iterrows():\n",
    "    nearby_count = count_nearby(attraction, restaurants, max_km=0.5)\n",
    "    accessibility_data.append({\n",
    "        'attraction': attraction['name'],\n",
    "        'neighborhood': attraction['neighborhood'],\n",
    "        'nearby_restaurants': nearby_count,\n",
    "        'is_must_see': attraction.get('is_must_see', False)\n",
    "    })\n",
    "\n",
    "access_df = pd.DataFrame(accessibility_data).sort_values('nearby_restaurants', ascending=True)\n",
    "\n",
    "# Visualization\n",
    "colors = ['red' if x < 3 else 'orange' if x < 5 else 'green' for x in access_df['nearby_restaurants']]\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    y=access_df['attraction'],\n",
    "    x=access_df['nearby_restaurants'],\n",
    "    orientation='h',\n",
    "    marker_color=colors,\n",
    "    text=access_df['nearby_restaurants'],\n",
    "    textposition='outside'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='<b>Restaurant Accessibility by Attraction</b><br><sup>Number of restaurants within 500m walking distance</sup>',\n",
    "    xaxis_title='Nearby Restaurants',\n",
    "    yaxis_title='',\n",
    "    height=max(400, len(access_df) * 30),\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Summary\n",
    "print(\"\\nüçΩÔ∏è DINING ACCESSIBILITY SUMMARY\")\n",
    "print(\"=\" * 40)\n",
    "low_access = access_df[access_df['nearby_restaurants'] < 3]\n",
    "if len(low_access) > 0:\n",
    "    print(\"\\n‚ö†Ô∏è Attractions with limited dining (< 3 restaurants):\")\n",
    "    for _, row in low_access.iterrows():\n",
    "        print(f\"  ‚Ä¢ {row['attraction']} ({row['neighborhood']}): {row['nearby_restaurants']} restaurants\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ All attractions have adequate dining options nearby!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Data Quality Scorecard\n",
    "\n",
    "### Overall readiness assessment for Rome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate quality metrics\n",
    "metrics = {\n",
    "    'Total POIs': len(df),\n",
    "    'Categories Covered': df['category'].nunique(),\n",
    "    'Neighborhoods Covered': df['neighborhood'].nunique(),\n",
    "    'POIs with Coordinates': df[['latitude', 'longitude']].notna().all(axis=1).sum(),\n",
    "    'POIs with Descriptions': df['description'].notna().sum() if 'description' in df.columns else 0,\n",
    "    'POIs with Cost Info': df['cost_level'].notna().sum() if 'cost_level' in df.columns else 0,\n",
    "    'POIs with Persona Scores': len(df[available_group].dropna()) if available_group else 0,\n",
    "    'Attractions': len(df[df['category'] == 'attraction']),\n",
    "    'Restaurants': len(df[df['category'] == 'restaurant']),\n",
    "}\n",
    "\n",
    "# Scoring thresholds\n",
    "thresholds = {\n",
    "    'Total POIs': (50, 100, 200),  # (min, good, excellent)\n",
    "    'Categories Covered': (3, 4, 5),\n",
    "    'Neighborhoods Covered': (3, 5, 8),\n",
    "    'Attractions': (10, 20, 30),\n",
    "    'Restaurants': (15, 30, 50),\n",
    "}\n",
    "\n",
    "def get_score_status(metric, value, thresholds):\n",
    "    if metric not in thresholds:\n",
    "        return '‚úÖ', 'N/A'\n",
    "    min_t, good_t, exc_t = thresholds[metric]\n",
    "    if value >= exc_t:\n",
    "        return 'üåü', 'Excellent'\n",
    "    elif value >= good_t:\n",
    "        return '‚úÖ', 'Good'\n",
    "    elif value >= min_t:\n",
    "        return 'üü°', 'Adequate'\n",
    "    else:\n",
    "        return '‚ùå', 'Insufficient'\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìä ROME DATA QUALITY SCORECARD\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Metric':<30} {'Value':>10} {'Status':>15}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for metric, value in metrics.items():\n",
    "    icon, status = get_score_status(metric, value, thresholds)\n",
    "    print(f\"{metric:<30} {value:>10} {icon} {status:>10}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# Overall readiness\n",
    "critical_pass = all([\n",
    "    metrics['Total POIs'] >= 20,\n",
    "    metrics['Attractions'] >= 5,\n",
    "    metrics['Restaurants'] >= 5,\n",
    "    metrics['Neighborhoods Covered'] >= 3\n",
    "])\n",
    "\n",
    "if critical_pass:\n",
    "    print(\"\\n‚úÖ ROME IS READY FOR PRODUCTION\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è ROME NEEDS MORE DATA BEFORE LAUNCH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üåç City Expansion Framework\n",
    "\n",
    "## How We Scale to New Cities\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# City Expansion Checklist\n",
    "expansion_framework = {\n",
    "    'Phase 1: Data Collection': {\n",
    "        'tasks': [\n",
    "            'Identify key neighborhoods (5-10)',\n",
    "            'Collect 50+ attractions from Overture Maps',\n",
    "            'Collect 100+ restaurants',\n",
    "            'Gather opening hours & pricing',\n",
    "            'Obtain coordinates for all POIs'\n",
    "        ],\n",
    "        'data_sources': ['Overture Maps (free)', 'Google Places API', 'TripAdvisor', 'Local tourism boards'],\n",
    "        'estimated_effort': '2-3 days'\n",
    "    },\n",
    "    'Phase 2: Persona Scoring': {\n",
    "        'tasks': [\n",
    "            'Score each POI for 8 group types (family, couple, solo, etc.)',\n",
    "            'Score each POI for 10 vibes (cultural, foodie, adventure, etc.)',\n",
    "            'Add practical attributes (wheelchair access, kid-friendly)',\n",
    "            'Mark must-see attractions and hidden gems'\n",
    "        ],\n",
    "        'data_sources': ['Manual curation', 'Review sentiment analysis', 'Local expert input'],\n",
    "        'estimated_effort': '3-5 days'\n",
    "    },\n",
    "    'Phase 3: Embedding Generation': {\n",
    "        'tasks': [\n",
    "            'Generate description embeddings for all POIs',\n",
    "            'Create neighborhood embeddings',\n",
    "            'Build proximity relationships',\n",
    "            'Index in pgvector'\n",
    "        ],\n",
    "        'data_sources': ['BGE-small-en-v1.5 (free, local)'],\n",
    "        'estimated_effort': '1 day'\n",
    "    },\n",
    "    'Phase 4: Validation': {\n",
    "        'tasks': [\n",
    "            'Generate test itineraries for each persona',\n",
    "            'Verify restaurant accessibility',\n",
    "            'Check walkable zone coverage',\n",
    "            'Quality review by local expert'\n",
    "        ],\n",
    "        'data_sources': ['Internal testing', 'Local reviewer'],\n",
    "        'estimated_effort': '2 days'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üåç CITY EXPANSION FRAMEWORK\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "total_days = 0\n",
    "for phase, details in expansion_framework.items():\n",
    "    print(f\"\\n{phase}\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"‚è±Ô∏è  Estimated effort: {details['estimated_effort']}\")\n",
    "    print(f\"üìä Data sources: {', '.join(details['data_sources'])}\")\n",
    "    print(\"Tasks:\")\n",
    "    for task in details['tasks']:\n",
    "        print(f\"  ‚òê {task}\")\n",
    "    \n",
    "    # Extract days for total\n",
    "    effort = details['estimated_effort']\n",
    "    days = int(effort.split('-')[0]) if '-' in effort else int(effort.split()[0])\n",
    "    total_days += days\n",
    "\n",
    "print(f\"\\n{'=' * 70}\")\n",
    "print(f\"üìÖ TOTAL ESTIMATED TIME PER CITY: {total_days}-{total_days+4} days\")\n",
    "print(f\"üí∞ DATA COST: ~$0 (using free data sources + local embeddings)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum Data Requirements per City\n",
    "min_requirements = pd.DataFrame({\n",
    "    'Category': ['Attractions', 'Restaurants', 'Activities', 'Shopping', 'Nightlife', 'Neighborhoods'],\n",
    "    'Minimum': [15, 30, 10, 5, 5, 4],\n",
    "    'Recommended': [30, 60, 20, 15, 15, 8],\n",
    "    'Rome (Current)': [\n",
    "        len(df[df['category'] == 'attraction']),\n",
    "        len(df[df['category'] == 'restaurant']),\n",
    "        len(df[df['category'] == 'activity']),\n",
    "        len(df[df['category'] == 'shopping']) if 'shopping' in df['category'].values else 0,\n",
    "        len(df[df['category'] == 'nightlife']) if 'nightlife' in df['category'].values else 0,\n",
    "        df['neighborhood'].nunique()\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\nüìã MINIMUM DATA REQUIREMENTS PER CITY\")\n",
    "print(\"=\" * 60)\n",
    "print(min_requirements.to_string(index=False))\n",
    "\n",
    "# Visualize\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    name='Minimum',\n",
    "    x=min_requirements['Category'],\n",
    "    y=min_requirements['Minimum'],\n",
    "    marker_color='lightgray'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    name='Recommended',\n",
    "    x=min_requirements['Category'],\n",
    "    y=min_requirements['Recommended'],\n",
    "    marker_color='lightblue'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    name='Rome (Current)',\n",
    "    x=min_requirements['Category'],\n",
    "    y=min_requirements['Rome (Current)'],\n",
    "    marker_color=COLORS['primary']\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='<b>Data Requirements vs Current Coverage</b>',\n",
    "    barmode='group',\n",
    "    height=400,\n",
    "    xaxis_title='Category',\n",
    "    yaxis_title='POI Count'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proposed Expansion Roadmap\n",
    "roadmap = pd.DataFrame({\n",
    "    'City': ['Rome', 'Florence', 'Venice', 'Barcelona', 'Paris', 'London', 'Amsterdam', 'Prague'],\n",
    "    'Priority': ['‚úÖ Live', 'Phase 1', 'Phase 1', 'Phase 2', 'Phase 2', 'Phase 3', 'Phase 3', 'Phase 3'],\n",
    "    'Why': [\n",
    "        'Pilot city - Complete',\n",
    "        'Italy expansion, high demand',\n",
    "        'Italy expansion, unique experience',\n",
    "        'Top EU destination',\n",
    "        'Highest search volume',\n",
    "        'English-speaking market',\n",
    "        'Compact, walkable',\n",
    "        'Budget-friendly option'\n",
    "    ],\n",
    "    'Data Complexity': ['Medium', 'Low', 'Low', 'Medium', 'High', 'High', 'Low', 'Low'],\n",
    "    'Est. Timeline': ['Done', 'Week 1-2', 'Week 2-3', 'Week 4-5', 'Week 5-7', 'Week 8-10', 'Week 10-11', 'Week 11-12']\n",
    "})\n",
    "\n",
    "print(\"\\nüóìÔ∏è PROPOSED EXPANSION ROADMAP\")\n",
    "print(\"=\" * 80)\n",
    "print(roadmap.to_string(index=False))\n",
    "\n",
    "# Timeline visualization\n",
    "fig = px.timeline(\n",
    "    roadmap[roadmap['Priority'] != '‚úÖ Live'],\n",
    "    x_start=[f\"2024-01-{i*7+1:02d}\" for i in range(len(roadmap)-1)],\n",
    "    x_end=[f\"2024-01-{i*7+14:02d}\" for i in range(len(roadmap)-1)],\n",
    "    y='City',\n",
    "    color='Priority',\n",
    "    title='<b>City Expansion Timeline</b>'\n",
    ")\n",
    "fig.update_layout(height=400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìä Key Takeaways\n",
    "\n",
    "### What We Analyzed\n",
    "\n",
    "| Analysis | Finding | Action |\n",
    "|----------|---------|--------|\n",
    "| **Data Coverage** | Good category distribution | ‚úÖ Ready |\n",
    "| **Persona Fit** | Strong cultural/foodie, weaker nightlife | Add more nightlife POIs |\n",
    "| **Walkable Zones** | 8+ distinct zones identified | Use for day grouping |\n",
    "| **Restaurant Access** | Most attractions well-served | Flag outliers in itinerary |\n",
    "\n",
    "### Expansion Approach\n",
    "\n",
    "1. **Cost-Efficient**: Free data sources (Overture Maps) + local embeddings\n",
    "2. **Scalable**: ~8-12 days per city with defined process\n",
    "3. **Quality-Focused**: Manual persona scoring is our differentiator\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. ‚òê Complete Rome data (add 10-15 more restaurants)\n",
    "2. ‚òê Begin Florence data collection\n",
    "3. ‚òê Build automated data quality dashboard\n",
    "4. ‚òê Create persona scoring guidelines document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export summary for presentation\n",
    "summary = {\n",
    "    'analysis_date': pd.Timestamp.now().strftime('%Y-%m-%d'),\n",
    "    'city': 'Rome',\n",
    "    'total_pois': len(df),\n",
    "    'categories': df['category'].nunique(),\n",
    "    'neighborhoods': df['neighborhood'].nunique(),\n",
    "    'walkable_zones': n_zones,\n",
    "    'data_quality_score': 'Good' if critical_pass else 'Needs Work',\n",
    "    'recommended_additions': [\n",
    "        'More nightlife venues',\n",
    "        'Additional budget restaurants',\n",
    "        'Wellness/spa options'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Save\n",
    "output_path = Path('../data/processed')\n",
    "output_path.mkdir(exist_ok=True)\n",
    "\n",
    "with open(output_path / 'rome_analysis_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2, default=str)\n",
    "\n",
    "print(f\"\\n‚úÖ Analysis summary saved to {output_path / 'rome_analysis_summary.json'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
